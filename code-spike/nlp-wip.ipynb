{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9942138a-7d4b-4f6e-8a98-8dfbd603670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2\n"
     ]
    }
   ],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dc6e08-868f-483e-9632-9993d4746342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yousef/miniforge3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|████| 4580/4580 [00:00<00:00, 8693.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#@title add label to dataset\n",
    "\n",
    "# variant = xes_importer.Variants.ITERPARSE\n",
    "# parameters = {variant.value.Parameters.TIMESTAMP_SORT: True}\n",
    "# log = xes_importer.apply('Helpdesk.xes',parameters=parameters)\n",
    "\n",
    "# from pm4py.objects.conversion.log import converter as log_converter\n",
    "# df = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)\n",
    "\n",
    "# activities = {\n",
    "#     'Insert ticket':0,'Assign seriousness':1, 'Take in charge ticket':2, 'Resolve ticket':3,'Closed':4, 'Wait':5, 'Create SW anomaly':6, \n",
    "#        'Schedule intervention':7, 'RESOLVED':8, 'INVALID':9, 'VERIFIED':10,'Resolve SW anomaly':11, 'Require upgrade':12, 'DUPLICATE':13 }\n",
    "\n",
    "# # df['Activity'] = df['Activity'].apply(lambda x: activities.get(x, -1) if x else -1)\n",
    "# # df['case:concept:name'] = df['case:concept:name'].str[4:]\n",
    "\n",
    "# # df.drop(columns=['Unnamed: 0', 'concept:name', 'lifecycle:transition', 'org:resource', 'case:variant','Resource', 'case:creator','case:variant-index'] , inplace=True)\n",
    "# df.drop(columns=['Unnamed: 0'] , inplace=True)\n",
    "# df.rename(columns={'time:timestamp':'timestamp', 'Activity':'activity', 'case:concept:name':'case'}, inplace=True)\n",
    "# df_ = df.copy()\n",
    "# df['date'] = df['timestamp'].dt.date\n",
    "# df['hour'] = df['timestamp'].dt.hour\n",
    "# df['dayofweek'] = df['timestamp'].dt.dayofweek+1\n",
    "# df['dayofmonth'] = df['timestamp'].dt.day\n",
    "# df['dayofyear'] = df['timestamp'].dt.dayofyear\n",
    "# df['weekofyear'] = df['timestamp'].dt.isocalendar().week\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56308882-e6b5-43dd-b30b-b2e5ce7b37ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, eval, test size: (10, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2 starts A1 on C3608 at 2010-01-13 06:40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2 starts A1 on C2748 at 2010-01-13 10:26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R2 starts A1 on C4284 at 2010-01-13 10:30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  labels\n",
       "0  R2 starts A1 on C3608 at 2010-01-13 06:40     0.0\n",
       "1  R2 starts A1 on C2748 at 2010-01-13 10:26     0.0\n",
       "2  R2 starts A1 on C4284 at 2010-01-13 10:30     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def make_dataset(dataset, iloc_from, iloc_to):\n",
    "  df_ = dataset[['text','wip']].iloc[iloc_from:iloc_to]\n",
    "  df_ .columns = [\"text\", \"labels\"]\n",
    "  df_.reset_index(inplace=True,drop=True)\n",
    "  return df_\n",
    "\n",
    "# train_size = int(df.shape[0] / 5)*2\n",
    "train_size = 10\n",
    "eval_size = train_size\n",
    "test_size = train_size\n",
    "# test_size = df.shape[0]-train_size-eval_size\n",
    "\n",
    "print(f'train, eval, test size: {train_size, eval_size, test_size}')\n",
    "\n",
    "\n",
    "df = pd.read_csv('df_nlp_real.csv',usecols=['wip','text'],dtype={'text':'string','wip':'float'})\n",
    "train_df = make_dataset(df, 0,train_size)\n",
    "eval_df = make_dataset(df, train_size,train_size+eval_size)\n",
    "test_df = make_dataset(df, train_size+eval_size, train_size+eval_size+eval_size)\n",
    "display(train_df.head(3))\n",
    "# display(eval_df)\n",
    "# display(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df25ee9-f0d1-4c17-9145-5348dde7c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6a0a2-21f2-45ac-b80c-3257af16754f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
